{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad7a5a9-d665-4ee2-8462-5a4570383e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code goes with multiplication  insted of concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc46cb6-c440-4f78-9626-e2216a114b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_max_pool as gmp, global_add_pool as gap,global_mean_pool as gep,global_sort_pool\n",
    "from torch_geometric.utils import dropout_adj\n",
    "\n",
    "\n",
    "# GCN based model\n",
    "class GNNNet(torch.nn.Module):\n",
    "    def __init__(self, n_output=1, num_features_pro=54, num_features_mol=78, output_dim=128, dropout=0.2):\n",
    "        super(GNNNet, self).__init__()\n",
    "\n",
    "        print('GNNNet Loaded')\n",
    "        self.n_output = n_output\n",
    "        self.mol_conv1 = GCNConv(num_features_mol, num_features_mol)\n",
    "        self.mol_conv2 = GCNConv(num_features_mol, num_features_mol * 2)\n",
    "        self.mol_conv3 = GCNConv(num_features_mol * 2, num_features_mol * 4)\n",
    "        self.mol_fc_g1 = torch.nn.Linear(num_features_mol * 4, 1024)\n",
    "        self.mol_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        # self.pro_conv1 = GCNConv(embed_dim, embed_dim)\n",
    "        self.pro_conv1 = GCNConv(num_features_pro, num_features_pro)\n",
    "        self.pro_conv2 = GCNConv(num_features_pro, num_features_pro * 2)\n",
    "        self.pro_conv3 = GCNConv(num_features_pro * 2, num_features_pro * 4)\n",
    "        # self.pro_conv4 = GCNConv(embed_dim * 4, embed_dim * 8)\n",
    "        self.pro_fc_g1 = torch.nn.Linear(num_features_pro * 4, 1024)\n",
    "        self.pro_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # combined layers\n",
    "        self.fc1 = nn.Linear(output_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, self.n_output)\n",
    "\n",
    "    def forward(self, data_mol, data_pro):\n",
    "        # get graph input\n",
    "        mol_x, mol_edge_index, mol_batch = data_mol.x, data_mol.edge_index, data_mol.batch\n",
    "        # get protein input\n",
    "        target_x, target_edge_index, target_batch = data_pro.x, data_pro.edge_index, data_pro.batch\n",
    "\n",
    "        # target_seq=data_pro.target\n",
    "\n",
    "        # print('size')\n",
    "        # print('mol_x', mol_x.size(), 'edge_index', mol_edge_index.size(), 'batch', mol_batch.size())\n",
    "        # print('target_x', target_x.size(), 'target_edge_index', target_batch.size(), 'batch', target_batch.size())\n",
    "\n",
    "        x = self.mol_conv1(mol_x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
    "        x = self.mol_conv2(x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # mol_edge_index, _ = dropout_adj(mol_edge_index, training=self.training)\n",
    "        x = self.mol_conv3(x, mol_edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = gep(x, mol_batch)  # global pooling\n",
    "\n",
    "        # flatten\n",
    "        x = self.relu(self.mol_fc_g1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.mol_fc_g2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        xt = self.pro_conv1(target_x, target_edge_index)\n",
    "        xt = self.relu(xt)\n",
    "\n",
    "        # target_edge_index, _ = dropout_adj(target_edge_index, training=self.training)\n",
    "        xt = self.pro_conv2(xt, target_edge_index)\n",
    "        xt = self.relu(xt)\n",
    "\n",
    "        # target_edge_index, _ = dropout_adj(target_edge_index, training=self.training)\n",
    "        xt = self.pro_conv3(xt, target_edge_index)\n",
    "        xt = self.relu(xt)\n",
    "\n",
    "        # xt = self.pro_conv4(xt, target_edge_index)\n",
    "        # xt = self.relu(xt)\n",
    "        xt = gep(xt, target_batch)  # global pooling\n",
    "\n",
    "        # flatten\n",
    "        xt = self.relu(self.pro_fc_g1(xt))\n",
    "        xt = self.dropout(xt)\n",
    "        xt = self.pro_fc_g2(xt)\n",
    "        xt = self.dropout(xt)\n",
    "\n",
    "        # print(x.size(), xt.size())\n",
    "        #  not concat ! multiple applid\n",
    "        # xc = torch.cat((x, xt), 1)\n",
    "        xc = x * xt\n",
    "        # print(xc.size())\n",
    "        # add some dense layers\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7202099-031d-4a41-ac13-2a3a33becdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gep\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Suppress FutureWarning related to torch.load\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Define the load_sample function\n",
    "def load_sample(path):\n",
    "    # Load individual sample from file\n",
    "    sample = torch.load(path)\n",
    "    mol_data = sample[0]\n",
    "    pro_data = sample[1]\n",
    "    target = sample[2]\n",
    "\n",
    "    # Convert dictionaries to Data objects if necessary\n",
    "    if isinstance(mol_data, dict):\n",
    "        mol_data = Data(**mol_data)\n",
    "    if isinstance(pro_data, dict):\n",
    "        pro_data = Data(**pro_data)\n",
    "\n",
    "    # Ensure that 'x' attribute is set\n",
    "    if not hasattr(mol_data, 'x') or mol_data.x is None:\n",
    "        if hasattr(mol_data, 'features'):\n",
    "            mol_data.x = mol_data.features\n",
    "            del mol_data.features\n",
    "        else:\n",
    "            raise ValueError(\"mol_data does not have 'x' or 'features' attribute\")\n",
    "\n",
    "    if not hasattr(pro_data, 'x') or pro_data.x is None:\n",
    "        if hasattr(pro_data, 'features'):\n",
    "            pro_data.x = pro_data.features\n",
    "            del pro_data.features\n",
    "        else:\n",
    "            raise ValueError(\"pro_data does not have 'x' or 'features' attribute\")\n",
    "\n",
    "    # Ensure 'x' is a float tensor\n",
    "    if not isinstance(mol_data.x, torch.Tensor):\n",
    "        mol_data.x = torch.tensor(mol_data.x)\n",
    "    if not isinstance(pro_data.x, torch.Tensor):\n",
    "        pro_data.x = torch.tensor(pro_data.x)\n",
    "\n",
    "    if mol_data.x.dtype != torch.float:\n",
    "        mol_data.x = mol_data.x.float()\n",
    "    if pro_data.x.dtype != torch.float:\n",
    "        pro_data.x = pro_data.x.float()\n",
    "\n",
    "    # Adjust 'edge_index' for mol_data\n",
    "    # Ensure 'edge_index' is a tensor of type torch.long\n",
    "    if not isinstance(mol_data.edge_index, torch.Tensor):\n",
    "        mol_data.edge_index = torch.tensor(mol_data.edge_index, dtype=torch.long)\n",
    "    else:\n",
    "        mol_data.edge_index = mol_data.edge_index.long()\n",
    "\n",
    "    # Ensure 'edge_index' has shape [2, num_edges]\n",
    "    if mol_data.edge_index.shape[0] != 2:\n",
    "        mol_data.edge_index = mol_data.edge_index.t()\n",
    "\n",
    "    # Adjust 'edge_index' for pro_data\n",
    "    if not isinstance(pro_data.edge_index, torch.Tensor):\n",
    "        pro_data.edge_index = torch.tensor(pro_data.edge_index, dtype=torch.long)\n",
    "    else:\n",
    "        pro_data.edge_index = pro_data.edge_index.long()\n",
    "\n",
    "    if pro_data.edge_index.shape[0] != 2:\n",
    "        pro_data.edge_index = pro_data.edge_index.t()\n",
    "\n",
    "    # Set 'num_nodes' attribute to suppress warnings\n",
    "    mol_data.num_nodes = mol_data.x.size(0)\n",
    "    pro_data.num_nodes = pro_data.x.size(0)\n",
    "\n",
    "    return (mol_data, pro_data, target)\n",
    "\n",
    "# Define the batch_loader function\n",
    "def batch_loader(file_list, sample_dir, batch_size):\n",
    "    batch = []\n",
    "    for idx, file_name in enumerate(file_list):\n",
    "        sample_path = os.path.join(sample_dir, file_name)\n",
    "        sample = load_sample(sample_path)\n",
    "        batch.append(sample)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if len(batch) > 0:\n",
    "        yield batch\n",
    "\n",
    "# Define the evaluation metrics functions\n",
    "def get_mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def get_ci(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the concordance index between true and predicted values.\n",
    "    \"\"\"\n",
    "    pairs = itertools.combinations(range(len(y_true)), 2)\n",
    "    c = 0\n",
    "    s = 0\n",
    "    for i, j in pairs:\n",
    "        if y_true[i] != y_true[j]:\n",
    "            s += 1\n",
    "            if (y_true[i] < y_true[j] and y_pred[i] < y_pred[j]) or \\\n",
    "               (y_true[i] > y_true[j] and y_pred[i] > y_pred[j]):\n",
    "                c += 1\n",
    "            elif y_pred[i] == y_pred[j]:\n",
    "                c += 0.5\n",
    "    return c / s if s != 0 else 0\n",
    "\n",
    "def get_pearson(y_true, y_pred):\n",
    "    return pearsonr(y_true.flatten(), y_pred.flatten())[0]\n",
    "\n",
    "\n",
    "\n",
    "# Suppress FutureWarning related to torch.load\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4dec03-ac3d-4cae-9068-2f43742ef492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda.\n",
      "Using existing TrainingModel directory at prepared_samples/TrainingModel\n",
      "GNNNet Loaded\n",
      "Model is on device: cuda:0\n",
      "Loading checkpoint from prepared_samples/TrainingModel/model_epoch1.pt\n",
      "Resuming training from epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                          | 1/299 [04:05<20:19:58, 245.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300, Loss: 1.1101\n",
      "Checkpoint saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏                         | 2/299 [06:20<14:53:31, 180.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/300, Loss: 0.8842\n",
      "Checkpoint saved at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▎                         | 3/299 [08:31<12:58:37, 157.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/300, Loss: 0.8255\n",
      "Checkpoint saved at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▎                         | 4/299 [12:06<14:46:30, 180.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/300, Loss: 0.8007\n",
      "Checkpoint saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▍                         | 5/299 [14:39<13:55:03, 170.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/300, Loss: 0.7767\n",
      "Checkpoint saved at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▌                         | 6/299 [17:04<13:11:20, 162.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/300, Loss: 0.7626\n",
      "Checkpoint saved at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▌                         | 7/299 [18:59<11:52:30, 146.41s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300, Loss: 0.7402\n",
      "Checkpoint saved at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▋                         | 8/299 [20:43<10:45:34, 133.11s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/300, Loss: 0.7296\n",
      "Checkpoint saved at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▊                         | 9/299 [22:30<10:03:24, 124.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300, Loss: 0.7236\n",
      "Checkpoint saved at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▊                         | 10/299 [24:15<9:32:16, 118.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/300, Loss: 0.6977\n",
      "Checkpoint saved at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▉                         | 11/299 [26:06<9:18:24, 116.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/300, Loss: 0.6882\n",
      "Checkpoint saved at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|█                        | 12/299 [28:32<10:00:28, 125.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/300, Loss: 0.6697\n",
      "Checkpoint saved at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|█                        | 13/299 [31:23<11:02:57, 139.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300, Loss: 0.6518\n",
      "Checkpoint saved at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|█▏                       | 14/299 [34:11<11:42:43, 147.94s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/300, Loss: 0.6387\n",
      "Checkpoint saved at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|█▎                       | 15/299 [37:07<12:20:05, 156.36s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/300, Loss: 0.6215\n",
      "Checkpoint saved at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|█▎                       | 16/299 [39:00<11:15:15, 143.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/300, Loss: 0.6064\n",
      "Checkpoint saved at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|█▍                       | 17/299 [40:46<10:21:04, 132.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/300, Loss: 0.6013\n",
      "Checkpoint saved at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|█▌                        | 18/299 [42:31<9:39:57, 123.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/300, Loss: 0.5855\n",
      "Checkpoint saved at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|█▋                        | 19/299 [44:16<9:12:40, 118.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300, Loss: 0.5683\n",
      "Checkpoint saved at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|█▋                        | 20/299 [45:59<8:49:00, 113.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/300, Loss: 0.5583\n",
      "Checkpoint saved at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|█▊                        | 21/299 [47:41<8:30:48, 110.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/300, Loss: 0.5596\n",
      "Checkpoint saved at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|█▉                        | 22/299 [49:27<8:22:03, 108.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/300, Loss: 0.5375\n",
      "Checkpoint saved at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|██                        | 23/299 [51:13<8:16:27, 107.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/300, Loss: 0.5332\n",
      "Checkpoint saved at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|██                        | 24/299 [52:58<8:11:37, 107.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/300, Loss: 0.5190\n",
      "Checkpoint saved at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|██▏                       | 25/299 [54:45<8:08:30, 106.97s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/300, Loss: 0.5193\n",
      "Checkpoint saved at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██▎                       | 26/299 [56:32<8:07:39, 107.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/300, Loss: 0.5018\n",
      "Checkpoint saved at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██▎                       | 27/299 [58:18<8:03:37, 106.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/300, Loss: 0.4891\n",
      "Checkpoint saved at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|██▏                     | 28/299 [1:00:02<7:59:06, 106.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/300, Loss: 0.4877\n",
      "Checkpoint saved at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|██▎                     | 29/299 [1:01:48<7:56:50, 105.96s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/300, Loss: 0.4802\n",
      "Checkpoint saved at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|██▍                     | 30/299 [1:03:34<7:55:14, 106.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/300, Loss: 0.4723\n",
      "Checkpoint saved at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|██▍                     | 31/299 [1:05:19<7:51:24, 105.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/300, Loss: 0.4636\n",
      "Checkpoint saved at epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|██▌                     | 32/299 [1:07:03<7:48:04, 105.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/300, Loss: 0.4579\n",
      "Checkpoint saved at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|██▋                     | 33/299 [1:08:49<7:47:36, 105.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/300, Loss: 0.4496\n",
      "Checkpoint saved at epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|██▋                     | 34/299 [1:10:34<7:44:51, 105.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/300, Loss: 0.4485\n",
      "Checkpoint saved at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|██▊                     | 35/299 [1:12:19<7:43:01, 105.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300, Loss: 0.4295\n",
      "Checkpoint saved at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|██▉                     | 36/299 [1:14:04<7:40:14, 105.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/300, Loss: 0.4308\n",
      "Checkpoint saved at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|██▉                     | 37/299 [1:15:48<7:37:13, 104.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/300, Loss: 0.4243\n",
      "Checkpoint saved at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███                     | 38/299 [1:17:32<7:35:10, 104.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/300, Loss: 0.4183\n",
      "Checkpoint saved at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███▏                    | 39/299 [1:19:17<7:33:12, 104.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/300, Loss: 0.4117\n",
      "Checkpoint saved at epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███▏                    | 40/299 [1:21:00<7:30:19, 104.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/300, Loss: 0.4029\n",
      "Checkpoint saved at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|███▎                    | 41/299 [1:22:45<7:29:09, 104.46s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/300, Loss: 0.3967\n",
      "Checkpoint saved at epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|███▎                    | 42/299 [1:24:30<7:27:43, 104.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/300, Loss: 0.3893\n",
      "Checkpoint saved at epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|███▍                    | 43/299 [1:26:15<7:27:21, 104.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/300, Loss: 0.3826\n",
      "Checkpoint saved at epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|███▌                    | 44/299 [1:27:59<7:24:20, 104.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/300, Loss: 0.3844\n",
      "Checkpoint saved at epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|███▌                    | 45/299 [1:29:43<7:22:15, 104.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/300, Loss: 0.3793\n",
      "Checkpoint saved at epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|███▋                    | 46/299 [1:31:29<7:21:18, 104.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300, Loss: 0.3716\n",
      "Checkpoint saved at epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|███▊                    | 47/299 [1:33:12<7:17:30, 104.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/300, Loss: 0.3694\n",
      "Checkpoint saved at epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|███▊                    | 48/299 [1:34:56<7:15:58, 104.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300, Loss: 0.3654\n",
      "Checkpoint saved at epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|███▉                    | 49/299 [1:36:40<7:13:35, 104.06s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/300, Loss: 0.3579\n",
      "Checkpoint saved at epoch 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|████                    | 50/299 [1:38:26<7:14:39, 104.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/300, Loss: 0.3486\n",
      "Checkpoint saved at epoch 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|████                    | 51/299 [1:40:12<7:14:51, 105.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/300, Loss: 0.3485\n",
      "Checkpoint saved at epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|████▏                   | 52/299 [1:41:57<7:12:55, 105.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/300, Loss: 0.3381\n",
      "Checkpoint saved at epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|████▎                   | 53/299 [1:43:41<7:09:57, 104.87s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/300, Loss: 0.3353\n",
      "Checkpoint saved at epoch 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|████▎                   | 54/299 [1:45:24<7:05:13, 104.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300, Loss: 0.3334\n",
      "Checkpoint saved at epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|████▍                   | 55/299 [1:47:06<7:00:37, 103.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300, Loss: 0.3300\n",
      "Checkpoint saved at epoch 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|████▍                   | 56/299 [1:48:51<7:01:35, 104.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300, Loss: 0.3206\n",
      "Checkpoint saved at epoch 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|████▌                   | 57/299 [1:50:35<6:59:48, 104.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300, Loss: 0.3145\n",
      "Checkpoint saved at epoch 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|████▋                   | 58/299 [1:52:19<6:57:43, 104.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300, Loss: 0.3161\n",
      "Checkpoint saved at epoch 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|████▋                   | 59/299 [1:54:03<6:55:42, 103.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300, Loss: 0.3079\n",
      "Checkpoint saved at epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|████▊                   | 60/299 [1:55:46<6:53:15, 103.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300, Loss: 0.3033\n",
      "Checkpoint saved at epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|████▉                   | 61/299 [1:57:30<6:51:16, 103.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/300, Loss: 0.3036\n",
      "Checkpoint saved at epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|████▉                   | 62/299 [1:59:15<6:51:36, 104.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/300, Loss: 0.2958\n",
      "Checkpoint saved at epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|█████                   | 63/299 [2:00:58<6:47:38, 103.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/300, Loss: 0.2929\n",
      "Checkpoint saved at epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|█████▏                  | 64/299 [2:02:43<6:47:39, 104.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300, Loss: 0.2887\n",
      "Checkpoint saved at epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|█████▏                  | 65/299 [2:04:27<6:46:11, 104.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300, Loss: 0.3137\n",
      "Checkpoint saved at epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|█████▎                  | 66/299 [2:06:10<6:43:06, 103.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/300, Loss: 0.2858\n",
      "Checkpoint saved at epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|█████▍                  | 67/299 [2:07:56<6:43:48, 104.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/300, Loss: 0.2799\n",
      "Checkpoint saved at epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|█████▍                  | 68/299 [2:09:39<6:41:08, 104.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/300, Loss: 0.2750\n",
      "Checkpoint saved at epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|█████▌                  | 69/299 [2:11:23<6:38:57, 104.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/300, Loss: 0.2767\n",
      "Checkpoint saved at epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|█████▌                  | 70/299 [2:13:09<6:39:12, 104.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300, Loss: 0.2733\n",
      "Checkpoint saved at epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|█████▋                  | 71/299 [2:14:56<6:39:52, 105.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/300, Loss: 0.2692\n",
      "Checkpoint saved at epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|█████▊                  | 72/299 [2:16:40<6:37:22, 105.03s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/300, Loss: 0.2690\n",
      "Checkpoint saved at epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|█████▊                  | 73/299 [2:18:26<6:35:56, 105.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/300, Loss: 0.2615\n",
      "Checkpoint saved at epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|█████▉                  | 74/299 [2:20:10<6:33:33, 104.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/300, Loss: 0.2596\n",
      "Checkpoint saved at epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██████                  | 75/299 [2:21:55<6:31:22, 104.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/300, Loss: 0.2588\n",
      "Checkpoint saved at epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██████                  | 76/299 [2:23:39<6:28:43, 104.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/300, Loss: 0.2534\n",
      "Checkpoint saved at epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██████▏                 | 77/299 [2:25:24<6:27:13, 104.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/300, Loss: 0.2502\n",
      "Checkpoint saved at epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██████▎                 | 78/299 [2:27:05<6:21:57, 103.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/300, Loss: 0.2547\n",
      "Checkpoint saved at epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██████▎                 | 79/299 [2:28:49<6:20:26, 103.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/300, Loss: 0.2472\n",
      "Checkpoint saved at epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██████▍                 | 80/299 [2:30:31<6:16:33, 103.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300, Loss: 0.2453\n",
      "Checkpoint saved at epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██████▌                 | 81/299 [2:32:18<6:19:05, 104.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/300, Loss: 0.2428\n",
      "Checkpoint saved at epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██████▌                 | 82/299 [2:34:03<6:18:22, 104.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/300, Loss: 0.2444\n",
      "Checkpoint saved at epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██████▋                 | 83/299 [2:35:47<6:15:26, 104.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/300, Loss: 0.2393\n",
      "Checkpoint saved at epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██████▋                 | 84/299 [2:37:32<6:14:35, 104.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/300, Loss: 0.2318\n",
      "Checkpoint saved at epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██████▊                 | 85/299 [2:39:16<6:12:42, 104.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/300, Loss: 0.2314\n",
      "Checkpoint saved at epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██████▉                 | 86/299 [2:41:00<6:10:26, 104.35s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/300, Loss: 0.2293\n",
      "Checkpoint saved at epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██████▉                 | 87/299 [2:42:44<6:08:39, 104.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300, Loss: 0.2312\n",
      "Checkpoint saved at epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|███████                 | 88/299 [2:44:29<6:07:09, 104.41s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/300, Loss: 0.2279\n",
      "Checkpoint saved at epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███████▏                | 89/299 [2:46:16<6:07:57, 105.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/300, Loss: 0.2248\n",
      "Checkpoint saved at epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███████▏                | 90/299 [2:48:01<6:06:41, 105.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/300, Loss: 0.2332\n",
      "Checkpoint saved at epoch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███████▎                | 91/299 [2:49:46<6:04:26, 105.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/300, Loss: 0.2227\n",
      "Checkpoint saved at epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███████▍                | 92/299 [2:52:21<6:54:17, 120.08s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/300, Loss: 0.2204\n",
      "Checkpoint saved at epoch 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  31%|███████▍                | 93/299 [2:55:20<7:52:27, 137.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/300, Loss: 0.2167\n",
      "Checkpoint saved at epoch 94\n"
     ]
    }
   ],
   "source": [
    "#calculate metrics on training and testing data at the end of training\n",
    "def train_and_evaluate(sample_dir, num_epochs=100, test_size=0.2, lr=0.001):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Running on {device}.\")\n",
    "\n",
    "    sample_files = [f for f in os.listdir(sample_dir) if f.endswith('.pt')]\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files = train_test_split(sample_files, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Create a directory for the model checkpoint\n",
    "    training_model_dir = os.path.join(sample_dir, 'TrainingModel')\n",
    "    if not os.path.exists(training_model_dir):\n",
    "        os.makedirs(training_model_dir)\n",
    "        print(f\"Created directory for checkpoints at {training_model_dir}\")\n",
    "    else:\n",
    "        print(f\"Using existing TrainingModel directory at {training_model_dir}\")\n",
    "\n",
    "    # Determine input feature dimensions from your data\n",
    "    sample = load_sample(os.path.join(sample_dir, train_files[0]))\n",
    "    mol_data = sample[0]\n",
    "    pro_data = sample[1]\n",
    "\n",
    "    num_features_mol = mol_data.x.size(1)\n",
    "    num_features_pro = pro_data.x.size(1)\n",
    "\n",
    "    # Initialize the GNN model with correct input dimensions\n",
    "    model = GNNNet(\n",
    "        num_features_mol=num_features_mol,\n",
    "        num_features_pro=num_features_pro\n",
    "    ).to(device)\n",
    "    print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = MSELoss()\n",
    "\n",
    "    # Initialize starting epoch\n",
    "    start_epoch = 1\n",
    "\n",
    "    # Check for existing checkpoints in TrainingModel directory\n",
    "    existing_checkpoints = [f for f in os.listdir(training_model_dir)\n",
    "                            if f.endswith('.pt') and f.startswith('model_epoch')]\n",
    "\n",
    "    if existing_checkpoints:\n",
    "        # Find the latest checkpoint based on epoch number\n",
    "        latest_checkpoint = max(existing_checkpoints,\n",
    "                                key=lambda x: int(x.split('_epoch')[1].split('.pt')[0]))\n",
    "        checkpoint_path = os.path.join(training_model_dir, latest_checkpoint)\n",
    "        print(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        loaded_epoch = checkpoint['epoch']\n",
    "        start_epoch = loaded_epoch + 1\n",
    "        print(f\"Resuming training from epoch {start_epoch}\")\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting training from scratch.\")\n",
    "\n",
    "    # Training loop with progress bar over epochs\n",
    "    for epoch in tqdm(range(start_epoch, num_epochs + 1),\n",
    "                      desc=\"Training\", unit=\"epoch\"):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Prepare batch loader\n",
    "        batch_size = 200  # Adjust batch size as needed\n",
    "        batch_loader_iter = batch_loader(train_files, sample_dir, batch_size=batch_size)\n",
    "\n",
    "        for batch_samples in batch_loader_iter:\n",
    "            mol_data_list = []\n",
    "            pro_data_list = []\n",
    "            target_list = []\n",
    "\n",
    "            for sample in batch_samples:\n",
    "                mol_data = sample[0]\n",
    "                pro_data = sample[1]\n",
    "                target = sample[2]\n",
    "\n",
    "                mol_data_list.append(mol_data)\n",
    "                pro_data_list.append(pro_data)\n",
    "                target_list.append(target)\n",
    "\n",
    "            mol_batch = Batch.from_data_list(mol_data_list).to(device)\n",
    "            pro_batch = Batch.from_data_list(pro_data_list).to(device)\n",
    "            target = torch.tensor(target_list, dtype=torch.float32).view(-1).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(mol_batch, pro_batch)\n",
    "            loss = loss_fn(output.view(-1), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * len(batch_samples)\n",
    "\n",
    "        avg_loss = running_loss / len(train_files)\n",
    "        tqdm.write(f\"Epoch {epoch}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save the model and optimizer states after each epoch\n",
    "        checkpoint_filename = f\"model_epoch{epoch}.pt\"\n",
    "        checkpoint_path = os.path.join(training_model_dir, checkpoint_filename)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, checkpoint_path)\n",
    "        tqdm.write(f\"Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "    # Final evaluation on test data\n",
    "    print(\"\\nEvaluating model after training...\")\n",
    "    model.eval()\n",
    "\n",
    "    def evaluate(files):\n",
    "        total_preds, total_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            batch_loader_iter = batch_loader(files, sample_dir, batch_size=batch_size)\n",
    "\n",
    "            for batch_samples in batch_loader_iter:\n",
    "                mol_data_list = []\n",
    "                pro_data_list = []\n",
    "                target_list = []\n",
    "\n",
    "                for sample in batch_samples:\n",
    "                    mol_data = sample[0]\n",
    "                    pro_data = sample[1]\n",
    "                    target = sample[2]\n",
    "\n",
    "                    mol_data_list.append(mol_data)\n",
    "                    pro_data_list.append(pro_data)\n",
    "                    target_list.append(target)\n",
    "\n",
    "                mol_batch = Batch.from_data_list(mol_data_list).to(device)\n",
    "                pro_batch = Batch.from_data_list(pro_data_list).to(device)\n",
    "                target = torch.tensor(target_list, dtype=torch.float32).view(-1).to(device)\n",
    "\n",
    "                output = model(mol_batch, pro_batch)\n",
    "                total_preds.append(output.cpu().numpy())\n",
    "                total_labels.append(target.cpu().numpy())\n",
    "\n",
    "        # Convert lists to numpy arrays for evaluation\n",
    "        total_preds = np.concatenate(total_preds)\n",
    "        total_labels = np.concatenate(total_labels)\n",
    "\n",
    "        # Calculate metrics\n",
    "        mse = get_mse(total_labels, total_preds)\n",
    "        ci = get_ci(total_labels, total_preds)\n",
    "        pearson = get_pearson(total_labels, total_preds)\n",
    "\n",
    "        return mse, ci, pearson\n",
    "\n",
    "    train_mse, train_ci, train_pearson = evaluate(train_files)\n",
    "    test_mse, test_ci, test_pearson = evaluate(test_files)\n",
    "\n",
    "    print(f\"Final Training Metrics: MSE: {train_mse:.4f}, CI: {train_ci:.4f}, Pearson: {train_pearson:.4f}\")\n",
    "    print(f\"Final Test Metrics: MSE: {test_mse:.4f}, CI: {test_ci:.4f}, Pearson: {test_pearson:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_dir = 'prepared_samples'  # Adjust the path to your samples directory\n",
    "    num_epochs = 300  # Adjust the number of epochs as needed\n",
    "    test_size = 0.2   # Proportion of the dataset to include in the test split\n",
    "    learning_rate = 0.001  # Learning rate\n",
    "\n",
    "    # Run the training function\n",
    "    train_and_evaluate(\n",
    "        sample_dir,\n",
    "        num_epochs=num_epochs,\n",
    "        test_size=test_size,\n",
    "        lr=learning_rate\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da401538-20d4-4998-aa2c-319445970749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed12d47-be50-4824-9086-0dfa9779a104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcc6d5-aa2a-48cc-ba85-c2c12792552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_products = torch.sum(batch1 * batch2, dim=1, keepdim=True)\n",
    "print(\"Dot Products Shape with keepdim=True:\", dot_products.shape)  # Output: torch.Size([200, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d368970-1a36-4900-b9e9-84476bdf3e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ea6b5-8940-4136-9e8d-d4916119429a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e90c30-6b85-4ad7-b5e6-f8d326ef209a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
