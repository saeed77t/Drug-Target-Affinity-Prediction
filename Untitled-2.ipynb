{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/saeed/miniconda3/lib/python3.12/site-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined all FASTA files into: combined_proteins.fasta\n",
      "Running command: /home/saeed/miniconda3/bin/hhblits -i combined_proteins.fasta -d \"/home/saeed/Documents/base paper implementation/datasets_cs219\" -o output.hhr -oa3m output.a3m -cpu 8\n",
      "Error running HHblits:\n",
      "- 14:55:36.507 ERROR: Could find neither hhm_db nor a3m_db!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def combine_fasta_files(input_dir, output_file):\n",
    "    \"\"\"\n",
    "    Combine multiple FASTA files into one single file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for filename in os.listdir(input_dir):\n",
    "            if filename.endswith(\".fasta\"):\n",
    "                filepath = os.path.join(input_dir, filename)\n",
    "                with open(filepath, 'r') as infile:\n",
    "                    outfile.write(infile.read() + '\\n')\n",
    "    print(f\"Combined all FASTA files into: {output_file}\")\n",
    "\n",
    "def create_symbolic_links(a3m_ffdata, a3m_ffindex, cs219_ffdata, cs219_ffindex):\n",
    "    \"\"\"\n",
    "    Create symbolic links for the .ffdata and .ffindex files.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(cs219_ffdata):\n",
    "        os.symlink(a3m_ffdata, cs219_ffdata)\n",
    "        print(f\"Created symbolic link: {cs219_ffdata}\")\n",
    "\n",
    "    if not os.path.exists(cs219_ffindex):\n",
    "        os.symlink(a3m_ffindex, cs219_ffindex)\n",
    "        print(f\"Created symbolic link: {cs219_ffindex}\")\n",
    "\n",
    "def run_hhblits(bin_path, protein_file, db_path, output_hhr, output_a3m):\n",
    "    \"\"\"\n",
    "    Run HHblits on the combined FASTA file and capture any errors.\n",
    "    \"\"\"\n",
    "    cmd = f'{bin_path} -i {protein_file} -d \"{db_path}\" -o {output_hhr} -oa3m {output_a3m} -cpu 8'\n",
    "    print(f\"Running command: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"HHblits Output:\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error running HHblits:\")\n",
    "        print(e.stderr)\n",
    "\n",
    "# Define file paths\n",
    "input_dir = \"kiba_dataset/proteins\"  # Directory with individual FASTA files\n",
    "combined_fasta_file = \"combined_proteins.fasta\"  # Output combined FASTA file\n",
    "a3m_ffdata = \"/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08/uniclust30_2018_08_a3m.ffdata\"\n",
    "a3m_ffindex = \"/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08/uniclust30_2018_08_a3m.ffindex\"\n",
    "cs219_ffdata = \"/home/saeed/Documents/base paper implementation/datasets_cs219_cs219.ffdata\"\n",
    "cs219_ffindex = \"/home/saeed/Documents/base paper implementation/datasets_cs219_cs219.ffindex\"\n",
    "bin_path = \"/home/saeed/miniconda3/bin/hhblits\"\n",
    "db_path = \"/home/saeed/Documents/base paper implementation/datasets_cs219\"\n",
    "output_hhr = \"output.hhr\"\n",
    "output_a3m = \"output.a3m\"\n",
    "\n",
    "# Step 1: Combine all FASTA files into one\n",
    "combine_fasta_files(input_dir, combined_fasta_file)\n",
    "\n",
    "# Step 2: Create symbolic links for .ffdata and .ffindex files\n",
    "create_symbolic_links(a3m_ffdata, a3m_ffindex, cs219_ffdata, cs219_ffindex)\n",
    "\n",
    "# Step 3: Run HHblits on the combined FASTA file\n",
    "run_hhblits(bin_path, combined_fasta_file, db_path, output_hhr, output_a3m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: /home/saeed/miniconda3/bin/hhblits -i combined_proteins.fasta -d \"/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08_a3m_db\" -o output.hhr -oa3m output.a3m -cpu 8\n",
      "Error running HHblits:\n",
      "- 15:57:00.956 ERROR: In /opt/conda/conda-bld/hhsuite_1720673754217/work/src/ffindexdatabase.cpp:11: FFindexDatabase:\n",
      "\n",
      "- 15:57:00.956 ERROR: \tcould not open file '/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08_a3m_db_cs219.ffdata'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def run_hhblits(bin_path, protein_file, db_path, output_hhr, output_a3m):\n",
    "    cmd = f'{bin_path} -i {protein_file} -d \"{db_path}\" -o {output_hhr} -oa3m {output_a3m} -cpu 8'\n",
    "    print(f\"Running command: {cmd}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        print(\"HHblits Output:\", result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error running HHblits:\")\n",
    "        print(e.stderr)\n",
    "\n",
    "# Example usage\n",
    "bin_path = \"/home/saeed/miniconda3/bin/hhblits\"\n",
    "protein_file = \"combined_proteins.fasta\"\n",
    "db_path = \"/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08_a3m_db\"  # Corrected path to a3m_db\n",
    "output_hhr = \"output.hhr\"\n",
    "output_a3m = \"output.a3m\"\n",
    "\n",
    "run_hhblits(bin_path, protein_file, db_path, output_hhr, output_a3m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: /home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08/a3m_db.ffdata\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"/home/saeed/Documents/base paper implementation/datasets/uniclust30_2018_08/a3m_db.ffdata\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"File exists: {file_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the combined FASTA file into individual sequences...\n",
      "Splitting completed.\n",
      "Running HHblits on 229 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- 16:21:20.155 INFO: Searching 32053680 column state sequences.\n",
      "\n",
      "- 16:21:20.185 INFO: Searching 32053680 column state sequences.\n",
      "\n",
      "- 16:21:20.214 INFO: /home/saeed/Documents/base paper implementation/split_sequences/P29323.fasta is in A2M, A3M or FASTA format\n",
      "\n",
      "- 16:21:20.246 INFO: /home/saeed/Documents/base paper implementation/split_sequences/Q15118.fasta is in A2M, A3M or FASTA format\n",
      "\n",
      "- 16:21:20.408 INFO: Iteration 1\n",
      "\n",
      "- 16:21:20.408 INFO: Iteration 1\n",
      "\n",
      "- 16:21:20.913 INFO: Prefiltering database\n",
      "\n",
      "- 16:21:21.344 INFO: Prefiltering database\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll HHblits jobs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning HHblits on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(seq_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sequences...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mparallel_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_hhblits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll HHblits jobs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Paths (Adjust these paths according to your setup)\n",
    "input_fasta = \"/home/saeed/Documents/base paper implementation/combined_proteins.fasta\"\n",
    "split_sequences_dir = \"/home/saeed/Documents/base paper implementation/split_sequences\"\n",
    "alignments_dir = \"/home/saeed/Documents/base paper implementation/alignments\"\n",
    "database = \"/media/saeed/88420B84420B766A/UniRef30_2022_02_hhsuite/UniRef30_2022_02\"\n",
    "hhblits_path = \"/home/saeed/miniconda3/bin/hhblits\"  # If hhblits is not in PATH, provide the full path\n",
    "\n",
    "# Number of CPU cores to use for HHblits (adjust as needed)\n",
    "cpu_cores = 4\n",
    "\n",
    "# Number of parallel processes for HHblits\n",
    "parallel_processes = 4  # Adjust based on your system's capabilities\n",
    "\n",
    "def split_fasta(input_file, output_dir):\n",
    "    \"\"\"\n",
    "    Splits a multi-FASTA file into individual FASTA files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(input_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fasta\"):\n",
    "            seq_id = record.id.replace(\"/\", \"_\")  # Replace '/' to avoid directory issues\n",
    "            output_file = os.path.join(output_dir, f\"{seq_id}.fasta\")\n",
    "            with open(output_file, \"w\") as out_handle:\n",
    "                SeqIO.write(record, out_handle, \"fasta\")\n",
    "\n",
    "def run_hhblits(seq_file):\n",
    "    \"\"\"\n",
    "    Runs HHblits on a single sequence file.\n",
    "    \"\"\"\n",
    "    seq_name = os.path.splitext(os.path.basename(seq_file))[0]\n",
    "    output_file = os.path.join(alignments_dir, f\"{seq_name}.a3m\")\n",
    "    hhr_file = os.path.join(alignments_dir, f\"{seq_name}.hhr\")\n",
    "    \n",
    "    # Construct the HHblits command\n",
    "    hhblits_cmd = [\n",
    "        hhblits_path,\n",
    "        \"-i\", seq_file,\n",
    "        \"-d\", database,\n",
    "        \"-oa3m\", output_file,\n",
    "        \"-o\", hhr_file,\n",
    "        \"-n\", \"3\",\n",
    "        \"-e\", \"1e-5\",\n",
    "        \"-cpu\", str(cpu_cores)\n",
    "    ]\n",
    "    \n",
    "    # Run HHblits\n",
    "    try:\n",
    "        subprocess.run(hhblits_cmd, check=True)\n",
    "        print(f\"HHblits completed for {seq_name}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running HHblits on {seq_name}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Step 1: Split the combined FASTA file into individual sequences\n",
    "    print(\"Splitting the combined FASTA file into individual sequences...\")\n",
    "    split_fasta(input_fasta, split_sequences_dir)\n",
    "    print(\"Splitting completed.\")\n",
    "\n",
    "    # Step 2: Create the alignments directory if it doesn't exist\n",
    "    os.makedirs(alignments_dir, exist_ok=True)\n",
    "\n",
    "    # Step 3: Get a list of all sequence files\n",
    "    seq_files = [\n",
    "        os.path.join(split_sequences_dir, f)\n",
    "        for f in os.listdir(split_sequences_dir)\n",
    "        if f.endswith(\".fasta\")\n",
    "    ]\n",
    "\n",
    "    # Step 4: Run HHblits on each sequence using multiprocessing\n",
    "    print(f\"Running HHblits on {len(seq_files)} sequences...\")\n",
    "    with Pool(processes=parallel_processes) as pool:\n",
    "        pool.map(run_hhblits, seq_files)\n",
    "\n",
    "    print(\"All HHblits jobs completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HHblits on 229 sequences...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Paths (Adjust these paths according to your setup)\n",
    "proteins_dir = \"/home/saeed/Documents/base paper implementation/kiba_dataset/proteins\"\n",
    "alignments_dir = \"/home/saeed/Documents/base paper implementation/kiba_dataset/alignments\"\n",
    "database = \"/media/saeed/88420B84420B766A/UniRef30_2022_02_hhsuite/UniRef30_2022_02\"\n",
    "hhblits_path = \"/home/saeed/miniconda3/bin/hhblits\"  # Provide full path if hhblits is not in PATH\n",
    "\n",
    "# Number of CPU cores to use for HHblits (adjust as needed)\n",
    "cpu_cores = 6\n",
    "\n",
    "# Number of parallel processes for HHblits\n",
    "parallel_processes = 6 # Adjust based on your system's capabilities\n",
    "\n",
    "def run_hhblits(seq_file):\n",
    "    \"\"\"\n",
    "    Runs HHblits on a single sequence file.\n",
    "    \"\"\"\n",
    "    seq_name = os.path.splitext(os.path.basename(seq_file))[0]\n",
    "    output_a3m = os.path.join(alignments_dir, f\"{seq_name}.a3m\")\n",
    "    output_hhr = os.path.join(alignments_dir, f\"{seq_name}.hhr\")\n",
    "    \n",
    "    # Construct the HHblits command\n",
    "    hhblits_cmd = [\n",
    "        hhblits_path,\n",
    "        \"-i\", seq_file,\n",
    "        \"-d\", database,\n",
    "        \"-oa3m\", output_a3m,\n",
    "        \"-o\", output_hhr,\n",
    "        \"-n\", \"3\",\n",
    "        \"-e\", \"1e-5\",\n",
    "        \"-cpu\", str(cpu_cores)\n",
    "    ]\n",
    "    \n",
    "    # Run HHblits\n",
    "    try:\n",
    "        subprocess.run(hhblits_cmd, check=True)\n",
    "        print(f\"HHblits completed for {seq_name}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running HHblits on {seq_name}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Ensure the alignments directory exists\n",
    "    os.makedirs(alignments_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of all .fasta files in the proteins directory\n",
    "    seq_files = [\n",
    "        os.path.join(proteins_dir, f)\n",
    "        for f in os.listdir(proteins_dir)\n",
    "        if f.endswith(\".fasta\")\n",
    "    ]\n",
    "\n",
    "    # Run HHblits on each sequence using multiprocessing\n",
    "    print(f\"Running HHblits on {len(seq_files)} sequences...\")\n",
    "    with Pool(processes=parallel_processes) as pool:\n",
    "        pool.map(run_hhblits, seq_files)\n",
    "\n",
    "    print(\"All HHblits jobs completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running HHblits on 229 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/229 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Paths (Adjust these paths according to your setup)\n",
    "proteins_dir = \"/home/saeed/Documents/base paper implementation/kiba_dataset/proteins\"\n",
    "alignments_dir = \"/home/saeed/Documents/base paper implementation/kiba_dataset/alignments\"\n",
    "database = \"/media/saeed/88420B84420B766A/UniRef30_2022_02_hhsuite/UniRef30_2022_02\"\n",
    "hhblits_path = \"/home/saeed/miniconda3/bin/hhblits\"  # Provide full path if hhblits is not in PATH\n",
    "\n",
    "# Number of CPU cores to use for HHblits (adjust as needed)\n",
    "cpu_cores = 4\n",
    "\n",
    "# Number of parallel processes for HHblits\n",
    "parallel_processes = 4 # Adjust based on your system's capabilities\n",
    "\n",
    "def run_hhblits(args):\n",
    "    \"\"\"\n",
    "    Runs HHblits on a single sequence file.\n",
    "    \"\"\"\n",
    "    seq_file, seq_name, progress_queue = args\n",
    "    output_a3m = os.path.join(alignments_dir, f\"{seq_name}.a3m\")\n",
    "    output_hhr = os.path.join(alignments_dir, f\"{seq_name}.hhr\")\n",
    "    \n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Construct the HHblits command\n",
    "    hhblits_cmd = [\n",
    "        hhblits_path,\n",
    "        \"-i\", seq_file,\n",
    "        \"-d\", database,\n",
    "        \"-oa3m\", output_a3m,\n",
    "        \"-o\", output_hhr,\n",
    "        \"-n\", \"3\",\n",
    "        \"-e\", \"1e-5\",\n",
    "        \"-cpu\", str(cpu_cores)\n",
    "    ]\n",
    "    \n",
    "    # Run HHblits\n",
    "    try:\n",
    "        subprocess.run(hhblits_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        # Calculate time taken\n",
    "        elapsed_time = time.time() - start_time\n",
    "        # Send the time taken to the progress queue\n",
    "        progress_queue.put(elapsed_time)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Handle errors and send a negative time to indicate failure\n",
    "        progress_queue.put(-1)\n",
    "        print(f\"Error running HHblits on {seq_name}: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Ensure the alignments directory exists\n",
    "    os.makedirs(alignments_dir, exist_ok=True)\n",
    "\n",
    "    # Get a list of all .fasta files in the proteins directory\n",
    "    seq_files = [\n",
    "        (os.path.join(proteins_dir, f), os.path.splitext(f)[0])\n",
    "        for f in os.listdir(proteins_dir)\n",
    "        if f.endswith(\".fasta\")\n",
    "    ]\n",
    "\n",
    "    total_sequences = len(seq_files)\n",
    "    print(f\"Running HHblits on {total_sequences} sequences...\")\n",
    "\n",
    "    # Create a Manager to share data between processes\n",
    "    manager = Manager()\n",
    "    progress_queue = manager.Queue()\n",
    "\n",
    "    # Start the Pool of worker processes\n",
    "    with Pool(processes=parallel_processes) as pool:\n",
    "        # Use tqdm to display a progress bar\n",
    "        with tqdm(total=total_sequences, ncols=80) as pbar:\n",
    "            # Map the function with arguments including the progress queue\n",
    "            result = pool.map_async(run_hhblits, [(seq_file, seq_name, progress_queue) for seq_file, seq_name in seq_files])\n",
    "\n",
    "            processed_sequences = 0\n",
    "            total_time = 0.0\n",
    "\n",
    "            while not result.ready() or not progress_queue.empty():\n",
    "                # Check if there's new progress information\n",
    "                while not progress_queue.empty():\n",
    "                    elapsed_time = progress_queue.get()\n",
    "                    processed_sequences += 1\n",
    "                    if elapsed_time >= 0:\n",
    "                        total_time += elapsed_time\n",
    "                        avg_time_per_seq = total_time / processed_sequences\n",
    "                        est_total_time = avg_time_per_seq * total_sequences\n",
    "                        est_time_remaining = est_total_time - total_time\n",
    "                        # Update the progress bar description\n",
    "                        pbar.set_description(f\"Avg Time/Seq: {avg_time_per_seq:.2f}s, ETA: {est_time_remaining/60:.1f}m\")\n",
    "                    else:\n",
    "                        # Handle failed sequences if necessary\n",
    "                        pbar.set_description(f\"Sequence {processed_sequences} failed.\")\n",
    "                    pbar.update(1)\n",
    "                time.sleep(0.1)  # Avoid busy waiting\n",
    "\n",
    "            # Ensure all results are collected\n",
    "            result.wait()\n",
    "\n",
    "    print(\"All HHblits jobs completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
