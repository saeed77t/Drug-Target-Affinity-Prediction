{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467fa705-129e-4d80-8df5-108b10e3e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool as gep\n",
    "\n",
    "# GNN Model definition for molecule and protein graphs\n",
    "class GNNNet(torch.nn.Module):\n",
    "    def __init__(self, n_output=1, num_features_pro=54, num_features_mol=78, output_dim=128, dropout=0.2):\n",
    "        super(GNNNet, self).__init__()\n",
    "\n",
    "        print('GNNNet Loaded')\n",
    "        # Molecule GNN layers\n",
    "        self.mol_conv1 = GCNConv(num_features_mol, num_features_mol)\n",
    "        self.mol_conv2 = GCNConv(num_features_mol, num_features_mol * 2)\n",
    "        self.mol_conv3 = GCNConv(num_features_mol * 2, num_features_mol * 4)\n",
    "        self.mol_fc_g1 = torch.nn.Linear(num_features_mol * 4, 1024)\n",
    "        self.mol_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        # Protein GNN layers\n",
    "        self.pro_conv1 = GCNConv(num_features_pro, num_features_pro)\n",
    "        self.pro_conv2 = GCNConv(num_features_pro * 2, num_features_pro * 4)\n",
    "        self.pro_fc_g1 = torch.nn.Linear(num_features_pro * 4, 1024)\n",
    "        self.pro_fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Combined dense layers\n",
    "        self.fc1 = nn.Linear(2 * output_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, n_output)\n",
    "\n",
    "    def forward(self, data_mol, data_pro):\n",
    "        # Molecule forward pass\n",
    "        mol_x, mol_edge_index, mol_batch = data_mol.x, data_mol.edge_index, data_mol.batch\n",
    "        mol_x = self.mol_conv1(mol_x, mol_edge_index)\n",
    "        mol_x = self.relu(mol_x)\n",
    "        mol_x = self.mol_conv2(mol_x, mol_edge_index)\n",
    "        mol_x = self.relu(mol_x)\n",
    "        mol_x = self.mol_conv3(mol_x, mol_edge_index)\n",
    "        mol_x = gep(mol_x, mol_batch)  # global pooling\n",
    "        mol_x = self.relu(self.mol_fc_g1(mol_x))\n",
    "        mol_x = self.dropout(mol_x)\n",
    "        mol_x = self.mol_fc_g2(mol_x)\n",
    "\n",
    "        # Protein forward pass\n",
    "        pro_x, pro_edge_index, pro_batch = data_pro.x, data_pro.edge_index, data_pro.batch\n",
    "        pro_x = self.pro_conv1(pro_x, pro_edge_index)\n",
    "        pro_x = self.relu(pro_x)\n",
    "        pro_x = self.pro_conv2(pro_x, pro_edge_index)\n",
    "        pro_x = self.relu(pro_x)\n",
    "        pro_x = gep(pro_x, pro_batch)  # global pooling\n",
    "        pro_x = self.relu(self.pro_fc_g1(pro_x))\n",
    "        pro_x = self.dropout(pro_x)\n",
    "        pro_x = self.pro_fc_g2(pro_x)\n",
    "\n",
    "        # Concatenate molecule and protein features\n",
    "        xc = torch.cat((mol_x, pro_x), dim=1)\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb9a76-684e-4759-ac13-522d84667696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_38766/2191735966.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pro_graph = torch.load(pro_graph_path)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def load_graph(path):\n",
    "    # Load graphs from .pkl for molecules and .pt for proteins\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def prepare_dataset(filtered_dataset, molecule_graph_dir, protein_graph_dir):\n",
    "    dataset = []\n",
    "    \n",
    "    for index, row in filtered_dataset.iterrows():\n",
    "        # Load molecule graph based on Drug_ID\n",
    "        mol_graph_path = os.path.join(molecule_graph_dir, f\"{row['Drug_ID']}_graph.pkl\")\n",
    "        mol_graph = load_graph(mol_graph_path)\n",
    "\n",
    "        # Load protein graph based on Target_ID\n",
    "        pro_graph_path = os.path.join(protein_graph_dir, f\"{row['Target_ID']}_graph.pt\")\n",
    "        pro_graph = torch.load(pro_graph_path)\n",
    "        \n",
    "        # Load target (affinity value)\n",
    "        target = torch.tensor([row['Y']], dtype=torch.float)\n",
    "        \n",
    "        # Append tuple (mol_graph, pro_graph, target) to dataset\n",
    "        dataset.append((mol_graph, pro_graph, target))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Example usage for dataset preparation\n",
    "molecule_graph_dir = 'molecule_graphs/'  # Directory where molecule graphs are stored\n",
    "protein_graph_dir = 'ProteinGraphs/'  # Directory where protein graphs are stored\n",
    "filtered_dataset_path = 'filtered_KibaDataSet.csv'  # Path to the filtered dataset CSV\n",
    "\n",
    "# Load filtered dataset CSV\n",
    "filtered_dataset = pd.read_csv(filtered_dataset_path)\n",
    "\n",
    "# Prepare the dataset with molecule, protein graphs, and affinity scores\n",
    "prepared_dataset = prepare_dataset(filtered_dataset, molecule_graph_dir, protein_graph_dir)\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4f8409-e1b8-4a09-ab46-35224976ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def get_mse(labels, preds):\n",
    "    return mean_squared_error(labels, preds)\n",
    "\n",
    "def get_pearson(labels, preds):\n",
    "    return pearsonr(labels, preds)[0]\n",
    "\n",
    "def get_ci(labels, preds):\n",
    "    # Concordance Index (CI) implementation\n",
    "    n = 0\n",
    "    h_sum = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(i + 1, len(labels)):\n",
    "            if labels[i] != labels[j]:\n",
    "                n += 1\n",
    "                if (preds[i] < preds[j] and labels[i] < labels[j]) or (preds[i] > preds[j] and labels[i] > labels[j]):\n",
    "                    h_sum += 1\n",
    "                elif preds[i] == preds[j]:\n",
    "                    h_sum += 0.5\n",
    "    return h_sum / n if n > 0 else 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73eb7c92-85c0-44fd-83e6-0247c3980995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "def train_5fold_cross_validation(data, molecule_graphs, protein_graphs, num_epochs=1000, n_splits=5, lr=0.001):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Print if the model is on GPU or CPU\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Model is running on GPU.\")\n",
    "    else:\n",
    "        print(\"Model is running on CPU.\")\n",
    "\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True)\n",
    "    \n",
    "    # Prepare dataset and dataloaders\n",
    "    results = []\n",
    "    loss_fn = MSELoss()\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(data)):\n",
    "        print(f'Fold {fold + 1}/{n_splits}')\n",
    "        \n",
    "        train_data = data.iloc[train_idx]\n",
    "        test_data = data.iloc[test_idx]\n",
    "        \n",
    "        train_loader = DataLoader(prepare_dataset(train_data, molecule_graphs, protein_graphs), batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(prepare_dataset(test_data, molecule_graphs, protein_graphs), batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize model and optimizer\n",
    "        model = GNNNet().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                mol_data, pro_data, target = batch\n",
    "                optimizer.zero_grad()\n",
    "                output = model(mol_data.to(device), pro_data.to(device))\n",
    "                loss = loss_fn(output, target.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item()}\")\n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        total_preds, total_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                mol_data, pro_data, target = batch\n",
    "                output = model(mol_data.to(device), pro_data.to(device))\n",
    "                total_preds.append(output.cpu().numpy())\n",
    "                total_labels.append(target.cpu().numpy())\n",
    "\n",
    "        mse = get_mse(total_labels, total_preds)\n",
    "        ci = get_ci(total_labels, total_preds)\n",
    "        pearson = get_pearson(total_labels, total_preds)\n",
    "        print(f\"Fold {fold+1} - MSE: {mse}, CI: {ci}, Pearson: {pearson}\")\n",
    "\n",
    "        # Save the results for this fold\n",
    "        results.append((mse, ci, pearson))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a1d8e4-aa58-4187-b1ac-c2864d446d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def load_graph(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    print(\"graph is loaded \")\n",
    "\n",
    "def prepare_dataset(data, molecule_graphs, protein_graphs):\n",
    "    dataset = []\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        mol_graph_path = os.path.join(molecule_graphs, f\"{row['Drug_ID']}_graph.pkl\")\n",
    "        pro_graph_path = os.path.join(protein_graphs, f\"{row['Target_ID']}_graph.pt\")\n",
    "        \n",
    "        mol_graph = load_graph(mol_graph_path)\n",
    "        pro_graph = torch.load(pro_graph_path)\n",
    "        target = torch.tensor([row['Y']], dtype=torch.float)\n",
    "        \n",
    "        dataset.append((mol_graph, pro_graph, target))\n",
    "\n",
    "    print(\"Dataset is ready\")\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653fc68-0ac0-4e6e-a169-e3d027dc7c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is running on GPU.\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36879/4181204454.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pro_graph = torch.load(pro_graph_path)\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "molecule_graphs = 'molecule_graphs/'\n",
    "protein_graphs = 'ProteinGraphs/'\n",
    "filtered_dataset_path = 'filtered_KibaDataSet.csv'\n",
    "\n",
    "# Load filtered dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv(filtered_dataset_path)\n",
    "\n",
    "# Run 5-fold cross-validation training\n",
    "results = train_5fold_cross_validation(data, molecule_graphs, protein_graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0cdad-5cd3-443b-85dc-499320b6c0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
