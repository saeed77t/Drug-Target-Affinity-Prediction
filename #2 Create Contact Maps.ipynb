{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12494242-607e-4f4a-a757-ceb0ba0aebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins not in aligned data: []\n",
      "Proteins not in array: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the numpy array of protein and molecule affinities\n",
    "protein_affinity_array = np.load('data/kiba/affinity_data.npy')\n",
    "# Documents/base paper implementation/kiba_dataset/affinity_data.npy\n",
    "\n",
    "# Path to the aligned protein files\n",
    "aligned_protein_path = \"/home/saeed/Documents/base paper implementation/data/kiba/aln\"\n",
    "\n",
    "# Get list of aligned protein IDs from filenames\n",
    "aligned_protein_ids = [file.split('.aln')[0] for file in os.listdir(aligned_protein_path) if file.endswith('.aln')]\n",
    "\n",
    "# Get list of protein IDs from the numpy array\n",
    "array_protein_ids = protein_affinity_array[:, 0]\n",
    "\n",
    "# Find proteins in the array but not in the aligned data\n",
    "proteins_not_in_aligned = np.setdiff1d(array_protein_ids, aligned_protein_ids)\n",
    "\n",
    "# Find proteins in the aligned data but not in the array\n",
    "proteins_not_in_array = np.setdiff1d(aligned_protein_ids, array_protein_ids)\n",
    "\n",
    "# Results\n",
    "print(\"Proteins not in aligned data:\", proteins_not_in_aligned)\n",
    "print(\"Proteins not in array:\", proteins_not_in_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708383b2-dbfe-4951-ae21-99c5f14a3c45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 12:04:16.618209: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:04:16.618269: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:04:16.626497: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "2024-09-28 12:04:16.627399: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5de8580582b0 executing computations on platform Host. Devices:\n",
      "2024-09-28 12:04:16.627459: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "2024-09-28 12:04:16.627959: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:04:16.629983: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "2024-09-28 12:04:16.630547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5de8580582b0 executing computations on platform Host. Devices:\n",
      "2024-09-28 12:04:16.630572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 85516 tid 85516 thread 0 bound to OS proc set 0\n",
      "2024-09-28 12:04:16.630962: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-09-28 12:04:16.631417: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:04:16.635944: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "2024-09-28 12:04:16.636636: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5de8580582b0 executing computations on platform Host. Devices:\n",
      "2024-09-28 12:04:16.636677: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 85517 tid 85517 thread 0 bound to OS proc set 0\n",
      "2024-09-28 12:04:16.638941: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-09-28 12:04:16.639591: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799925000 Hz\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 85515 tid 85515 thread 0 bound to OS proc set 0\n",
      "2024-09-28 12:04:16.640739: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5de8580582b0 executing computations on platform Host. Devices:\n",
      "2024-09-28 12:04:16.640923: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "OMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\n",
      "2024-09-28 12:04:16.642939: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "OMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\n",
      "OMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-7\n",
      "OMP: Info #156: KMP_AFFINITY: 8 available OS procs\n",
      "OMP: Info #157: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #179: KMP_AFFINITY: 1 packages x 4 cores/pkg x 2 threads/core (4 total cores)\n",
      "OMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 0 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 1 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 2 thread 1 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0 \n",
      "OMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 3 thread 1 \n",
      "OMP: Info #250: KMP_AFFINITY: pid 85518 tid 85518 thread 0 bound to OS proc set 0\n",
      "2024-09-28 12:04:16.653893: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-09-28 12:04:16.731851: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2024-09-28 12:04:16.739607: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2024-09-28 12:04:16.747065: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "2024-09-28 12:04:16.761985: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "/home/saeed/miniconda3/envs/pconsc4_env/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/kiba/aln/Q96L34.aln\n",
      "Processing data/kiba/aln/Q16513.aln\n",
      "Processing data/kiba/aln/Q14289.aln\n",
      "Processing data/kiba/aln/O00329.aln\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 1 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #254: KMP_AFFINITY: pid 85516 tid 85516 thread 0 bound to OS proc set 0\n",
      "OMP: Info #155: KMP_AFFINITY: Initial OS proc set respected: 0\n",
      "OMP: Info #216: KMP_AFFINITY: decoding x2APIC ids.\n",
      "OMP: Info #157: KMP_AFFINITY: 1 available OS procs\n",
      "OMP: Info #158: KMP_AFFINITY: Uniform topology\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"LL cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L3 cache\" is equivalent to \"socket\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L2 cache\" is equivalent to \"core\".\n",
      "OMP: Info #287: KMP_AFFINITY: topology layer \"L1 cache\" is equivalent to \"core\".\n",
      "OMP: Info #192: KMP_AFFINITY: 1 socket x 1 core/socket x 1 thread/core (1 total cores)\n",
      "OMP: Info #218: KMP_AFFINITY: OS proc to physical thread map:\n",
      "OMP: Info #172: KMP_AFFINITY: OS proc 0 maps to socket 0 core 0 thread 0 \n",
      "OMP: Info #254: KMP_AFFINITY: pid 85515 tid 85515 thread 0 bound to OS proc set 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pconsc4\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Function to predict and save contact map for a single protein\n",
    "def predict_single_protein(input_file, output_file):\n",
    "    # Load the pconsc4 model inside the separate process\n",
    "    model = pconsc4.get_pconsc4()\n",
    "\n",
    "    try:\n",
    "        print(f'Processing {input_file}')\n",
    "        pred = pconsc4.predict(model, input_file)  # Predict the contact map\n",
    "        np.save(output_file, pred['cmap'])  # Save the contact map in .npy format\n",
    "        print(f'{output_file} saved.')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {input_file}: {e}')\n",
    "\n",
    "    finally:\n",
    "        # Clear the Keras session and reset the TensorFlow graph to release memory\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "\n",
    "def pconsc4Prediction(aligned_protein_path, contact_map_dir, num_workers=4):\n",
    "    # Ensure the contact maps directory exists\n",
    "    if not os.path.exists(contact_map_dir):\n",
    "        os.makedirs(contact_map_dir)\n",
    "\n",
    "    # Get list of aligned protein files\n",
    "    file_list = os.listdir(aligned_protein_path)\n",
    "    random.shuffle(file_list)  # Randomize the order of processing\n",
    "\n",
    "    tasks = []\n",
    "    # Iterate through each alignment file and generate contact maps\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        for file in file_list:\n",
    "            input_file = os.path.join(aligned_protein_path, file)\n",
    "            output_file = os.path.join(contact_map_dir, file.split('.aln')[0] + '.npy')  # Store as .npy file\n",
    "            \n",
    "            if os.path.exists(output_file):\n",
    "                continue  # Skip if the contact map already exists\n",
    "            \n",
    "            # Submit tasks to process the files in parallel\n",
    "            tasks.append(executor.submit(predict_single_protein, input_file, output_file))\n",
    "        \n",
    "        # Wait for all tasks to complete\n",
    "        for task in tasks:\n",
    "            task.result()  # This ensures we capture any exceptions raised during the execution\n",
    "\n",
    "# Paths\n",
    "aligned_protein_path = \"data/kiba/aln\"\n",
    "contact_map_dir = \"KibaContactMaps\"\n",
    "\n",
    "# Run the prediction using 4 CPU cores\n",
    "pconsc4Prediction(aligned_protein_path, contact_map_dir, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178288f8-31a4-4cc2-9d50-225c401ef9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #GOOD working ON 1 CPU core !\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pconsc4\n",
    "# import random\n",
    "# import tensorflow as tf\n",
    "# from multiprocessing import Process\n",
    "\n",
    "# def predict_single_protein(input_file, output_file):\n",
    "#     # Load the pconsc4 model within the separate process\n",
    "#     model = pconsc4.get_pconsc4()\n",
    "\n",
    "#     try:\n",
    "#         print(f'Processing {input_file}')\n",
    "#         pred = pconsc4.predict(model, input_file)  # Predict the contact map\n",
    "#         np.save(output_file, pred['cmap'])  # Save the contact map in .npy format\n",
    "#         print(f'{output_file} saved.')\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f'Error processing {input_file}: {e}')\n",
    "#     finally:\n",
    "#         # Clear the Keras session to release memory\n",
    "#         tf.keras.backend.clear_session()\n",
    "#         tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# def pconsc4Prediction(aligned_protein_path, contact_map_dir):\n",
    "#     # Ensure the contact maps directory exists\n",
    "#     if not os.path.exists(contact_map_dir):\n",
    "#         os.makedirs(contact_map_dir)\n",
    "\n",
    "#     # Get list of aligned protein files\n",
    "#     file_list = os.listdir(aligned_protein_path)\n",
    "#     random.shuffle(file_list)  # Randomize the order of processing\n",
    "\n",
    "#     # Iterate through each alignment file and spawn a separate process\n",
    "#     for file in file_list:\n",
    "#         input_file = os.path.join(aligned_protein_path, file)\n",
    "#         output_file = os.path.join(contact_map_dir, file.split('.aln')[0] + '.npy')  # Store as .npy file\n",
    "\n",
    "#         if os.path.exists(output_file):\n",
    "#             continue  # Skip if the contact map already exists\n",
    "\n",
    "#         # Spawn a new process for each prediction\n",
    "#         p = Process(target=predict_single_protein, args=(input_file, output_file))\n",
    "#         p.start()\n",
    "#         p.join()  # Wait for the process to finish before moving to the next file\n",
    "\n",
    "# # Paths\n",
    "# aligned_protein_path = \"data/kiba/aln\"\n",
    "# contact_map_dir = \"KibaContactMaps\"\n",
    "\n",
    "# # Run the prediction\n",
    "# pconsc4Prediction(aligned_protein_path, contact_map_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf73cc-f20f-4153-80ec-d64b0fae9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pconsc4\n",
    "# import random\n",
    "\n",
    "# def pconsc4Prediction(aligned_protein_path, contact_map_dir):\n",
    "#     model = pconsc4.get_pconsc4()  # Load the pconsc4 model\n",
    "    \n",
    "#     # Ensure the contact maps directory exists\n",
    "#     if not os.path.exists(contact_map_dir):\n",
    "#         os.makedirs(contact_map_dir)\n",
    "    \n",
    "#     # Get list of aligned protein files\n",
    "#     file_list = os.listdir(aligned_protein_path)\n",
    "#     random.shuffle(file_list)  # Randomize the order of processing\n",
    "    \n",
    "#     # Iterate through each alignment file and generate contact maps\n",
    "#     for file in file_list:\n",
    "#         input_file = os.path.join(aligned_protein_path, file)\n",
    "#         output_file = os.path.join(contact_map_dir, file.split('.aln')[0] + '.npy')  # Store as .npy file\n",
    "        \n",
    "#         if os.path.exists(output_file):\n",
    "#             continue  # Skip if the contact map already exists\n",
    "        \n",
    "#         try:\n",
    "#             print(f'Processing {input_file}')\n",
    "#             pred = pconsc4.predict(model, input_file)  # Predict the contact map\n",
    "#             np.save(output_file, pred['cmap'])  # Save the contact map in .npy format\n",
    "#             print(f'{output_file} saved.')\n",
    "#         except Exception as e:\n",
    "#             print(f'Error processing {file}: {e}')\n",
    "\n",
    "# # Paths\n",
    "# aligned_protein_path = \"data/kiba/aln\"\n",
    "# contact_map_dir = \"KibaContactMaps\"\n",
    "\n",
    "# # Run the prediction\n",
    "# pconsc4Prediction(aligned_protein_path, contact_map_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002d875-8ea1-4e43-8e9c-22c84ee4a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pconsc4\n",
    "# import random\n",
    "# import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "\n",
    "# def pconsc4Prediction(aligned_protein_path, contact_map_dir):\n",
    "#     model = pconsc4.get_pconsc4()  # Load the pconsc4 model\n",
    "\n",
    "#     # Ensure the contact maps directory exists\n",
    "#     if not os.path.exists(contact_map_dir):\n",
    "#         os.makedirs(contact_map_dir)\n",
    "    \n",
    "#     # Get list of aligned protein files\n",
    "#     file_list = os.listdir(aligned_protein_path)\n",
    "#     random.shuffle(file_list)  # Randomize the order of processing\n",
    "\n",
    "#     # Iterate through each alignment file and generate contact maps\n",
    "#     for file in file_list:\n",
    "#         input_file = os.path.join(aligned_protein_path, file)\n",
    "#         output_file = os.path.join(contact_map_dir, file.split('.aln')[0] + '.npy')  # Store as .npy file\n",
    "        \n",
    "#         if os.path.exists(output_file):\n",
    "#             continue  # Skip if the contact map already exists\n",
    "        \n",
    "#         try:\n",
    "#             print(f'Processing {input_file}')\n",
    "#             pred = pconsc4.predict(model, input_file)  # Predict the contact map\n",
    "#             np.save(output_file, pred['cmap'])  # Save the contact map in .npy format\n",
    "#             print(f'{output_file} saved.')\n",
    "            \n",
    "#             # Clear Keras session to release memory\n",
    "#             K.clear_session()\n",
    "#             tf.compat.v1.reset_default_graph()\n",
    "#         except Exception as e:\n",
    "#             print(f'Error processing {file}: {e}')\n",
    "\n",
    "# # Paths\n",
    "# aligned_protein_path = \"data/kiba/aln\"\n",
    "# contact_map_dir = \"KibaContactMaps\"\n",
    "\n",
    "# # Run the prediction\n",
    "# pconsc4Prediction(aligned_protein_path, contact_map_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9fde15-06ca-47fb-b111-b227aad5e991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pconsc4\n",
    "# import random\n",
    "# import tensorflow as tf\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# def predict_contact_map(model, input_file, output_file):\n",
    "#     try:\n",
    "#         print(f'Processing {input_file}')\n",
    "        \n",
    "#         # Predict the contact map\n",
    "#         pred = pconsc4.predict(model, input_file)\n",
    "        \n",
    "#         # Save the contact map in .npy format\n",
    "#         np.save(output_file, pred['cmap'])\n",
    "#         print(f'{output_file} saved.')\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f'Error processing {input_file}: {e}')\n",
    "#     finally:\n",
    "#         # Clear TensorFlow session to free up memory after each task\n",
    "#         tf.keras.backend.clear_session()\n",
    "\n",
    "# def process_in_parallel(aligned_protein_path, contact_map_dir, num_workers=4):\n",
    "#     model = pconsc4.get_pconsc4()  # Load the pconsc4 model\n",
    "\n",
    "#     # Ensure the contact maps directory exists\n",
    "#     if not os.path.exists(contact_map_dir):\n",
    "#         os.makedirs(contact_map_dir)\n",
    "\n",
    "#     # Get list of aligned protein files\n",
    "#     file_list = os.listdir(aligned_protein_path)\n",
    "#     random.shuffle(file_list)  # Randomize the order of processing\n",
    "\n",
    "#     # Use a process pool to handle parallel execution\n",
    "#     with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#         futures = []\n",
    "#         for file in file_list:\n",
    "#             input_file = os.path.join(aligned_protein_path, file)\n",
    "#             output_file = os.path.join(contact_map_dir, file.split('.aln')[0] + '.npy')\n",
    "            \n",
    "#             # Skip already processed files\n",
    "#             if os.path.exists(output_file):\n",
    "#                 continue\n",
    "\n",
    "#             # Submit the job to the pool\n",
    "#             futures.append(executor.submit(predict_contact_map, model, input_file, output_file))\n",
    "\n",
    "#         # Wait for all futures to complete\n",
    "#         for future in futures:\n",
    "#             try:\n",
    "#                 future.result()  # Ensure any exceptions are caught\n",
    "#             except Exception as e:\n",
    "#                 print(f'Error in parallel execution: {e}')\n",
    "\n",
    "# # Paths\n",
    "# aligned_protein_path = \"/home/saeed/Documents/base paper implementation/data/kiba/aln\"\n",
    "# contact_map_dir = \"/home/saeed/Documents/base paper implementation/KibaContactMaps\"\n",
    "\n",
    "# # Run the prediction with parallelism\n",
    "# process_in_parallel(aligned_protein_path, contact_map_dir, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f2ff8-731b-4d85-9d8d-e4562feabe41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
